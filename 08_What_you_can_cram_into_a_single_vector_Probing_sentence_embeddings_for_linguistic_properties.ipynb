{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "08 What you can cram into a single vector: Probing sentence embeddings for linguistic properties.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyOeiWTOobOrfnA2QoJH7MvZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jinsusong/study-paper-review/blob/main/08_What_you_can_cram_into_a_single_vector_Probing_sentence_embeddings_for_linguistic_properties.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# What you can cram into a single vector: Probing sentence embeddings for linguistic properties \n",
        "## ACL"
      ],
      "metadata": {
        "id": "IDeqZkcd6DBK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ABSTRACT\n",
        "\n",
        "- 양질의 문장 임베딩들이 많이 등장하고 있지만, 임베딩들이 어떤 언어학적 지식을 가지고 있는 지에 대해서는 아직 아는 바가 별로 없음. \n",
        "\n",
        "- 다운스트림 태스크에서의 성능으로 임베딩이 지닌 언어학적 특질을 분석하기엔 한계점이 있음. 왜냐하면 태스크의 복잡성으로 인해 representation 그자체가 지니고 있는 정보를 추론하기 힘들기 때문.\n",
        "\n",
        "- 따라서 본 논문에서는 문장 임베딩 (=문장 표현)이 포착하고 있는 언어학적 특질을 탐구하기 위한 10가지 probing task를 제안함."
      ],
      "metadata": {
        "id": "ou3971WPHcjZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introduction \n"
      ],
      "metadata": {
        "id": "xc6KtnyW6Gz_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 문장 임베딩 기법이 NLP tasks에서 인상깊은 결과를 달성함.\n",
        "    - Machine translation, entailment detection 등\n",
        "\n",
        "- 이로 인하여 universal embeddings에 대한 관심이 증대됨\n",
        "    - 임베딩 모델을 한 번 훈련시킨 후 다양한 분야에서 활용하는 방식\n",
        "\n",
        "- Sentence embedding이 문장의 중요한 언어학적 속성을 포착하는 것으로 보임\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "x4xrgrPU-2aW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Downstream task는 복잡한 형태의 추론을 필요로 하므로, 모델이 문장 내의 어떤 정보에 의존하는지를 특정하기 어려움.\n",
        "    - 모델은 일반적으로 임의의 결과(what)를 도출할 수 있으나, 근거(how)는 도출하지 못함. 또한, 복잡한 task는 hidden biases를 유도할 수 있음.\n",
        "\n",
        "문장 임베딩의 속성 분석 기법: model introspction\n",
        "    - 문장 인코더가 문장의 어떤 속성을 유지하는지 알아보고자 함 \n",
        "    - 해당 기법들은 인코더의 아키텍처에 의존적이기 때문에 여러 인코더 간의 비교를 위해 사용하기에는 적합하지 않다는 한계가 존재함.\n",
        "\n",
        "    보충설명 \n",
        "        - 신경망 기반의 word embedding 모델은 기존 sparse vetor space representations와 달리 해석 불가능함\n",
        "        - 모델에 의하여 어떤 종류의 정보가 포착되는지를 분석하기 위한 모든 기법을 총칭하는 말이 model introspection\n",
        "        0\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "8fHhhRkF_SK_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "문장 임베딩을 이용한 모델들이 다운스트림 태스크에서 좋은 성능을 기록하는 것으로 보아, 아마 이것들이 문장의 중요한 언어학적 특질들을 포착하고 있는 것이 아닐까 추론해볼 수 있음. 하지만 다운스트림 태스크가 지니는 복잡성으로 인해, 문장 임베딩 모델들이 정확히 어떤 언어학적 지식을 인코딩하고 있는 지 알기가 쉽지 않음. 또 언어학적 지식을 갖추고 있지 않음에도 단순히 휴리스틱만을 이용해 다운스트림 태스크를 (잘) 수행하는 경우도 많이 있으므로, 복잡한 태스크 결과만을 놓고 문장 임베딩의 언어학적 지식을 평가하는 것은 위험한 행동임. "
      ],
      "metadata": {
        "id": "awGwGUxMH9se"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Probing Task 개념의 등장 \n",
        "\n",
        "임베딩에게 특정 언어학 지식을 묻는 단순한 분류 태스크를 수행하게 함. 맞힌다면 해당 사전학습된 representation에는 그 문제를 푸는 데 필요한 언어학 지식이 인코딩되어 있는 것. \n",
        "\n",
        "-Probing Task의 특징 \n",
        "\n",
        "- 해석의 문제를 최소화하기 위해, probing task는 간단한 사항을 묻는다.\n",
        "\n",
        "- 다운스트리밍 태스크와 비교했을 때 간단하며 태스크의 바이어스(*가령 모델이 단순 휴리스틱을 이용해 태스크를 수행하는 것을 막는 것) 를 통제하기 쉽다. \n",
        "\n",
        "- 벡터 표현을 내놓는 인코더라면, 인코더의 아키텍처는 probing task와 무관하다. \n",
        "\n",
        "- 이 논문은 다양한 probing task를 제안하고, probing task를 이용해 인코더 모델들을 체계적으로 평가하는 방법론과 툴, 예시를 보여줬다는 점에서 의의가 있음. "
      ],
      "metadata": {
        "id": "7aFWj3QEIRf6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Model "
      ],
      "metadata": {
        "id": "w5zi5B_kWZFG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "연구 방법 \n",
        "probing task에 대한 연구를 크게 확장하여 10가지의 prbing tasks를 제안함\n",
        "    - 각 task는 probe하려는 언어학적 속성의 유형에 따라 구분됨\n",
        "Probing task methodology를 체계화함\n",
        "    - 가능한 뉘앙스 요인을 통제함\n",
        "    - 단일 문장 표현만을 입력으로 받도록 모든 task를 프레이밍함\n",
        "    - 보편성을 최대화하고 결과 해석이 쉽도록 함 \n",
        "\n",
        "제안된 probing task를 활용하여 다양한 SOTA encoder 및 training methods를 탐색하고 Probing and downstream task의 성능을 비교함\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "K7juT1bjIouc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Probing benchmarks 구성 시 고려한 4가지 기준 \n",
        "1. 보편성과 해석가능성을 위하여 , 모든 분류 문제는 하나의 문장 임베딩만을 입력으로 요구해야함\n",
        "\n",
        "2. 관련 속성이 문장 벡처에 비선형적으로 인코딩된 경우에 대비하여, 대규모 분류기를 학습시킬 대규모 훈련 세트를 구성할 수 있어야 함 \n",
        "\n",
        "3. 어휘 단서 또는 문장 길이와 같은 뉘앙스 변수들이 통제되어야 함 \n",
        "\n",
        "4. 흥미로운 언어학적 속성을 분석하는 tasks가 필요함 \n",
        "\n",
        "\n",
        " "
      ],
      "metadata": {
        "id": "ia9ifHZHL_WP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task "
      ],
      "metadata": {
        "id": "PT-KXiZBWeWJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Surface information \n",
        "    - 문장 임베딩이 문장의 피상적 속성을 얼마나 잘 보존하는지 평가함\n",
        "\n",
        "    1. Task. SentLen: 문장의 길이 예측 \n",
        "\n",
        "2. Surface information\n",
        "    1. Task WC : 문장 임베딩 벡터로부터 문장의 원래 단어에 대한 정보를 복구할 수 있는지 테스트 \n",
        "\n",
        "3. Syntactic information\n",
        "    1. Task Bshift : 인코더가 어순에 민감한지 평가 \n",
        "\n",
        "    2. Task TreeDepth : 인코더가 문장의 계층적 구조를 추론하는지 평가\n",
        "\n",
        "    3. Task TopConst : 문장을 최상위 constituent의 순서로 분류할 수 있는지 평가 \n",
        "\n",
        "\n",
        "4. Semantic information\n",
        "    1. Task Tense : 주절 동사의 시제에 따른 문장 분류 \n",
        "    2. Task SubjNum : 주절 내 주어의 수 분류 \n",
        "    3. Task ObjNum : 주절 내 직접 목적어의 수 분류 \n",
        "    4. Task SOMO : 임의의 명사 또는 동사를 다른 명사 또는 동사로 교체하여 문장을 수정한 후, 문장이 수정되었는지 여부를 분류 \n",
        "    5. Task Coordlnv : 두 개의 등위절로 구성된 문장 데이터셋 중 절반 문장에서 절의 순서를 교체, 문장이 수정되었는지 여부를 분류 \n",
        "    \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "U7cu6T7RM80q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusion"
      ],
      "metadata": {
        "id": "ILCj5hwhVNPw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 문장 임베딩 방법의 언어학적 지식을 probe 할 수 있는 일련의 task 소개 \n",
        "- 최신 문장 인코더의 언어학적 평가를 실시하여 인코더가 baseline이상으로 다양한 언어학적 속성을 포착하고 있다는 것을 밝혀냄\n",
        "- probing task와 복잡한 downstream task 간의 연관성 패턴을 밝혀내고 다양한 임베딩 방법의 언어학적 속성에 대한 흥미로운 발견을 제시함.\n",
        "- 동일한 목적 하에 학습한 다른 인코더 구조가 비슷한 성능을 내더라도 임베딩은 다를 수 있다. - > 문장 임베딩에 있어 아키텍처의 중요성 지적\n",
        "\n",
        "- 특히 BiLSTM-max 임베딩이 학습 전에도 이미 흥미로운 언어학적 지식을 포착하고 있으며, 학습 후에는 anomaly에 노출된 적이 없어도 의미론적 수용 가능성을 평가할 수 있다는 점을 발견함\n",
        "- 우리의 public하게 공개된 task set이 새로운 인코더의 언어학적 속성을 평가할 수 있는 벤치마킨 툴이 되고, 이것이 인코더가 무엇을 학습하는가에 대한 더 나은 이해로 나아가기를 희망함.\n"
      ],
      "metadata": {
        "id": "69c0Ao8UVPGn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 출처 : https://blog.naver.com/xoxojess/222230386512\n",
        "- 출처 : https://www.youtube.com/watch?v=FavuvQKIzaU"
      ],
      "metadata": {
        "id": "465zRFu6O7wd"
      }
    }
  ]
}