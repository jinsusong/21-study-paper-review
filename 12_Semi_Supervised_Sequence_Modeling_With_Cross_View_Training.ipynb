{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "12 Semi-Supervised Sequence Modeling With Cross-View Training.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyMYqN6fygZ9UFcF0gLuhbAt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jinsusong/study-paper-review/blob/main/12_Semi_Supervised_Sequence_Modeling_With_Cross_View_Training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Semi-Supervised Sequence Modeling With Cross-View Training (EMNLP)"
      ],
      "metadata": {
        "id": "do2CMQXSoBrn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Abstract"
      ],
      "metadata": {
        "id": "hYfhTvWwoGHX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "word2vec 및 ELMo와 같은 비지도 표현 학습 알고리즘은 주로 레이블이 없는 많은 텍스트를 이용할 수 있기 때문에 많은 Supervised NLP 모델의 정확도를 향상시킨다.\n",
        "\n",
        "그러나 Supervised 모델은 기본 교육 단계 동안에만 작업별 레이블링된 데이터로부터 학습한다. \n",
        "\n",
        "따라서 레이블링된 데이터와 레이블링되지 않은 데이터를 혼합하여 Bi-LSTM 문장 인코더의 표현을 개선하는 준지도 학습 알고리즘인 CVT(Cross-View Training)를 제안한다. \n",
        "\n",
        "라벨링된 examples에서는 standard supervised learning이 사용된다. \n",
        "\n",
        "레이블이 없는 examples에서, CVT는 전체 입력을 보는 전체 모델의 예측과 일치하도록 입력의 제한된 보기(예: 문장의 일부만)를 보는 보조 예측 모듈을 가르친다. \n",
        "\n",
        "보조 모듈과 전체 모델은 중간 표현을 공유하므로, 이는 차례로 전체 모델을 개선한다. \n",
        "\n",
        "또한, 우리는 CVT가 멀티태스킹 학습과 결합할 때 특히 효과적이라는 것을 보여준다. \n",
        "\n",
        "우리는 다섯 가지 시퀀스 태그 지정 작업, 기계 번역 및 의존성 구문 분석에 대해 CVT를 평가하여 최첨단 결과를 달성한다."
      ],
      "metadata": {
        "id": "u5z6sGGLlMt2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Introduction"
      ],
      "metadata": {
        "id": "GhuI4AuxmmIn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "딥 러닝 모델은 대량의 레이블링 데이터에 대해 훈련할 때 가장 잘 작동한다. \n",
        "\n",
        "그러나 레이블을 취득하는 것은 비용이 많이 들기 때문에 레이블이 없는 examples를 활용하는 효과적인 반지도 학습 기법이 필요하다. \n",
        "\n",
        "신경 NLP에 대한 널리 성공적인 준지도 학습 전략은 pre-training word vectors이다. \n",
        "\n",
        "보다 최근의 연구는 Bi-LSTM 문장 인코더가 언어 모델링을 수행하도록 훈련시킨 다음 그 문맥에 민감한 표현을 supervised models에 통합한다\n",
        "\n",
        "이러한 pre-training 방법은 레이블이 없는 데이터의 대규모 말뭉치에 대해 unsupervised representation learning 을 수행한 후 supervised training.을 수행한다. \n",
        "\n",
        "pre-training의 주요 단점은 first 표현 학습 단계가 라벨링된 데이터를 활용하지 않는다는 것이다. \n",
        "\n",
        "이 모델은 특정 작업을 대상으로 하는 표현보다는 일반적으로 효과적인 표현을 학습하려고 시도한다. \n",
        "\n",
        "자가 훈련과 같은 오래된 준지도 학습 알고리즘은 레이블링된 데이터와 레이블링되지 않은 데이터의 혼합에 대한 작업에 대해 지속적으로 학습하기 때문에 이 문제를 겪지 않는다. \n",
        "\n",
        "self-training은 역사적으로 NLP에 효과적이지만(Yarowsky, 1995; McClosky 등, 2006) 신경 모델에서는 덜 사용된다. \n",
        "\n",
        "이 논문은 신경 시퀀스 모델에 잘 작동하는 새로운 self-training 알고리즘인 크로스 뷰 트레이닝(CVT)을 제시한다. \n",
        "\n",
        "self-training에서 모델은 레이블이 지정된 예제에 대해 정상적으로 학습합니다. \n",
        "\n",
        "레이블이 없는 예제에서 모델은 예제에 대한 예측을 하는 두 분석가이자 이러한 예측에 대해 훈련된 학생으로 작용한다. \n",
        "\n",
        "이 프로세스는 일부 작업에 대한 가치를 보여주었지만 다소 일관적이다. \n",
        "\n",
        "이 모델은 이미 훈련 중인 예측을 생산한다. \n",
        "\n",
        "컴퓨터 비전에 대한 최근 연구는 학생의 입력에 노이즈를 추가하고 입력 동요에 강하도록 모델을 훈련함으로써 이를 해결한다\n",
        "\n",
        "그러나 텍스트와 같은 이산 입력에는 노이즈를 적용하는 것이 어렵다. \n",
        "\n",
        "해결책으로, 우리는 멀티뷰 학습에서 영감을 얻고 입력의 다양한 뷰에 걸쳐 일관된 예측을 생성하도록 모델을 훈련한다. \n",
        "\n",
        "CVT는 학생으로서 전체 모델을 훈련시키는 대신, 보조 예측 모듈(벡터 표현을 예측으로 변환하는 신경 네트워크)을 모델에 추가하고 학생으로서 훈련시킨다. \n",
        "\n",
        "각 학생 예측 모듈에 대한 입력은 입력 예제의 제한된 보기에 해당하는 모델의 중간 표현들의 집합이다. 예를 들어, 시퀀스 태깅을 위한 하나의 보조 예측 모듈은 모델의 첫 번째 BiLSTM 레이어에 있는 \"앞으로\" LSTM에만 부착되어 있기 때문에 현재 모델의 오른쪽에 있는 토큰을 보지 않고 예측을 한다. CVT는 모델의 표현 학습을 개선함으로써 작동합니다. 보조 예측 모듈은 전체 모델이 입력에 대한 더 나은 무제한 뷰를 가지고 있기 때문에 전체 모델의 예측으로부터 배울 수 있다. 보조 모듈은 입력에 대한 제한된 보기에도 불구하고 정확한 예측을 하는 방법을 배우면 그 위에 구축된 표현의 품질을 향상시킨다. 따라서 동일한 공유 표현을 사용하는 전체 모델이 개선됩니다. 간단히 말해서, 우리의 방법은 레이블이 없는 데이터에 대한 표현 학습 아이디어를 고전적인 자가 훈련과 결합한다. CVT는 다양한 작업과 신경 구조에 적용할 수 있지만 예측 모듈이 공유 Bi-LSTM 인코더에 연결되는 시퀀스 모델링 작업에 중점을 둔다. 시퀀스 태거, 그래프 기반 종속성 파서 및 시퀀스 대 시퀀스 모델에 잘 작동하는 보조 예측 모듈을 제안한다. 영어 의존성 구문 분석, 조합 범주형 문법 슈퍼태깅, 명명된 엔티티 인식, 음성 일부 태그 지정 및 텍스트 청킹과 영어에서 베트남어 기계 번역에 대한 접근 방식을 평가한다. CVT는 이러한 모든 작업에 대해 이전에 발표된 결과보다 개선된다. 또한 CVT는 다중 작업 학습과 쉽고 효과적으로 결합할 수 있다. 우리는 공유 Bi-LSTM 인코더 위에 다양한 작업에 대한 예측 모듈을 추가하기만 하면 된다. 기계 번역을 제외한 모든 작업을 공동으로 수행하도록 통합 모델을 훈련하면 총 훈련 시간을 줄이면서 결과(다중 작업 ELMo 모델보다 성능이 우수)가 개선된다."
      ],
      "metadata": {
        "id": "wap1vqxxmnrV"
      }
    }
  ]
}